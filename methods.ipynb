{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Samples and genome sequencing\n",
    "\n",
    "Estimate phylogenetic tree with published short reads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "raxml-ng \\\n",
    "  --msa bernese_variable_positions.fasta \\\n",
    "  --all --model GTR+G --tree pars{10} --bs-trees 100 --threads 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genome assembly and variant calling\n",
    "\n",
    "The assembly pipeline is available as a Snakemake workflow on: http://git.scicore.unibas.ch/TBRU/PacbioSnake\n",
    "\n",
    "Create a pangenome graph from the concatenated single contig assemblies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pggb_latest.sif pggb \\\n",
    "  -i single_contig_assemblies.fasta.gz \\\n",
    "  -o ./pggb \\\n",
    "  -t 4 \\\n",
    "  -n 16 \\\n",
    "  -p 99 \\\n",
    "  -s 5k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call variants from the pangenome graph, using N1426 as a positional reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pggb_latest.sif vg deconstruct \\\n",
    "  pggb/single_contig_assemblies.fasta.gz.*.smooth.final.gfa -d1 -e \\\n",
    "    -p N1426_1 \\\n",
    "    -t 4 \\\n",
    "    --all-snarls \\\n",
    "    > variants.vcf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assembly validation and curation\n",
    "\n",
    "The alignment of long reads against the assembly built from them is part of the [assembly pipeline](https://git.scicore.unibas.ch/TBRU/PacbioSnake/-/blob/scicore/workflow/rules/mapreads.smk).\n",
    "\n",
    "Call variants from the aligned long reads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "while read STRAIN; do\n",
    "\n",
    "    ASSEMBLY=${STRAIN}.fasta\n",
    "    READS=${STRAIN}/remapping/longreads.bam\n",
    "    \n",
    "    freebayes -p 1 -f ${ASSEMBLY} ${READS} | gzip > ${STRAIN}.var.vcf.gz\n",
    "\n",
    "done < samples.txt\n",
    "\n",
    "# Get  inconsistent sites (GT==1):\n",
    "for VCF in *.vcf.gz; do \n",
    "    STRAIN=$(echo $VCF | cut -d'.' -f1)\n",
    "    vcftools --gzvcf ${STRAIN}.var.vcf.gz --extract-FORMAT-info GT --stdout | awk '$3==1' >> inconsistent_sites.tsv\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gene and repeat annotation\n",
    "\n",
    "Gene annotation with bakta is part of the [assembly pipeline](https://git.scicore.unibas.ch/TBRU/PacbioSnake/-/blob/scicore/workflow/rules/annotate.smk).\n",
    "\n",
    "Annotate insertion sequences with ISEScan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "isescan.py \\\n",
    "--seqfile ${ASSEMBLY} \\\n",
    "--output isescan \\\n",
    "--nthread 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Annotate short sequence repeats (<= 9bp) with kmer-ssr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "kmer-ssr \\\n",
    "  -i ../$ASSEMBLY \\\n",
    "  -o $STRAIN.SSRs.tsv \\\n",
    "  -p 2-9 -r 3 -t 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Annotate tandem repeats (>9bp) with SPADES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "SPADE.py -in $ASSEMBLY -n 4 -v Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Annotate homopolymers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import sys\n",
    "from Bio import SeqIO\n",
    "\n",
    "try:\n",
    "    fasta = sys.argv[1]\n",
    "    min_len = int(sys.argv[2])\n",
    "    \n",
    "except IndexError:\n",
    "    sys.exit(\"Usage: annotate_homopolymers.py <genome.fasta> <minimum tract length>. Writes to stdout.\")\n",
    "\n",
    "for seq_record in SeqIO.parse(fasta, \"fasta\"):\n",
    "    \n",
    "    contig = seq_record.id\n",
    "    \n",
    "    previous = ''\n",
    "    counter = 0\n",
    "    \n",
    "    for i, base in enumerate(seq_record.seq):\n",
    "        \n",
    "        # initiate\n",
    "        if base == previous and counter == 0:\n",
    "            counter = 2\n",
    "            \n",
    "        # extent\n",
    "        elif base == previous and counter > 0:\n",
    "            counter += 1\n",
    "        \n",
    "        # terminate\n",
    "        elif base != previous:\n",
    "                if counter >= min_len:\n",
    "                    outline = map(str, [contig, i-counter, i-1, counter, previous])\n",
    "                    sys.stdout.write(\"\\t\".join(outline) +'\\n')\n",
    "                    #print(contig, i-counter, i-1, counter, previous)\n",
    "                    counter = 0\n",
    "                    \n",
    "                else:\n",
    "                    counter = 0\n",
    "                    \n",
    "        previous = base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify interspersed repeats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "nucmer --maxmatch --nosimplify $GENOME $GENOME\n",
    "show-coords out.delta -Tcdl > delta.out.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter delta out file\n",
    "\n",
    "import seaborn\n",
    "import pandas as pd\n",
    "\n",
    "stats = {\n",
    "    \"overlap\": 0,\n",
    "    \"identical\" : 0,\n",
    "    \"keep\" : 0\n",
    "}\n",
    "\n",
    "header = ['S1','E1','S2','E2','LEN1','LEN2', 'PID','LENR','LENQ','COVR','COVQ','RFRM', 'QFRM','TAG1', 'TAG2']\n",
    "\n",
    "t = pd.read_csv(\"delta.out.tsv\", skiprows=[0,1,2,3], sep='\\t', names=header)\n",
    "\n",
    "print(t.describe())\n",
    "t.head()\n",
    "\n",
    "# Remove self hits\n",
    "start_diff = t['S1'] != t['S2']\n",
    "end_diff = t['E1'] != t['E2']\n",
    "t = t[start_diff | end_diff]\n",
    "\n",
    "# Remove overlapping\n",
    "overlap_filter = t['S2'] > t['E1']\n",
    "t = t[overlap_filter]\n",
    "\n",
    "# Remove dissimilar\n",
    "id_filt = t['PID'] > 90\n",
    "t = t[id_filt]\n",
    "\n",
    "# Minimum length?\n",
    "print(seaborn.displot(t['PID'], kind=\"kde\"))\n",
    "print(seaborn.displot(t['LEN1'], kind=\"kde\"))\n",
    "print(seaborn.displot(t, x=\"LEN1\", y=\"PID\", kind=\"kde\", logx=True))\n",
    "\n",
    "# Write filtered table\n",
    "t.to_csv(\"delta.out.filtered.tsv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intersect annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "bedtools intersect -a bernese.variants.bed -b N1426.CDS.gff3 $INSERTIONSEQS $REPEATS $HPS $SSR $HOMSEGS -wao \\\n",
    "-names bakta insertion_sequences repeats homopolymers SSR homologysegments \\\n",
    "> bernese.variants.intersects.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identification of gene conversion tracts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract conversion tracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "OG=../B_call_variants/pggb/single_contig_assemblies.fasta.gz.d71a954.eb0f3d3.33064a1.smooth.final.og\n",
    "GENOME=../../assembly/N1392/N1392.fasta\n",
    "\n",
    "# Coordinates of suspected conversion tracts in the reference\n",
    "FIRST_TRACT_POS=1640207\n",
    "LAST_TRACT_POS=1640702\n",
    "\n",
    "# Liftover coordinates to the genome in which the variants were called\n",
    "pggb_latest.sif odgi position \\\n",
    "  -i $OG \\\n",
    "  -p N1426_1,$FIRST,+ \\\n",
    "  -r N1377_1 \n",
    "\n",
    "pggb_latest.sif odgi position \\\n",
    "  -i $OG \\\n",
    "  -p N1426_1,$LAST,+ \\\n",
    "  -r N1377_1\n",
    "\n",
    "# Get sequence of conversion tract\n",
    "samtools faidx \\\n",
    "  $GENOME \\\n",
    "  N1392_1:$((1640207 - 5))-$((1640702 + 5)) > N1392.PE_PGRS28.conversion_tract.fasta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Blast conversion tracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "blastn \\\n",
    "  -query N1392.PE_PGRS28.conversion_tract.fasta \\\n",
    "  -subject ../../assembly/N1392/N1392.fasta \\\n",
    "  -word_size 7 \\\n",
    "  -outfmt \"6 qseqid sseqid pident length mismatch gapopen qstart qend sstart send evalue bitscore\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with Illumina data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get SNPs in the core genome from the pangenome graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variants = 'variants.vcf'  # variants called from the pangenome graph\n",
    "reference = 'N1426_1'\n",
    "\n",
    "keep = []\n",
    "\n",
    "discarded = {\n",
    "    \"Not SNP\" : 0,\n",
    "    \"Missing genotypes\" : 0,\n",
    "    \"Invariant\" : 0\n",
    "}\n",
    "\n",
    "with open(variants) as f:\n",
    "    \n",
    "    for line in f:\n",
    "        \n",
    "        if line.startswith(\"#CHROM\"):\n",
    "            \n",
    "            fields = line.strip().split(\"\\t\")\n",
    "            strains = fields[9:]\n",
    "\n",
    "            # Dictionary to store SNPs for each strain\n",
    "            strain_seqs = {strain : \"\" for strain in strains}\n",
    "            strain_seqs[reference] = \"\"\n",
    "            continue\n",
    "        \n",
    "        elif line.startswith(\"#\"):\n",
    "            continue\n",
    "\n",
    "        fields = line.strip().split(\"\\t\")\n",
    "        position = int(fields[1])\n",
    "        \n",
    "        ref = fields[3]\n",
    "        alt = fields[4].split(\",\")\n",
    "        \n",
    "        gt = fields[9:]\n",
    "        \n",
    "        # Skip rows with missing genotypes\n",
    "        if len(gt) != len(strains):\n",
    "            print('Missing genotypes', fields)\n",
    "            continue\n",
    "        \n",
    "        # Only SNPs\n",
    "        if len(ref) > 1 or any(len(x) > 1 for x in alt):\n",
    "            discarded[\"Not SNP\"] += 1\n",
    "            continue\n",
    "\n",
    "        # Exclude missing genotypes\n",
    "        if any(x in gt for x in [\"\", \".\"]):\n",
    "            discarded[\"Missing genotypes\"] += 1\n",
    "            #continue\n",
    "\n",
    "        # Write alleles to site\n",
    "        alleles = [ref] + alt       \n",
    "        site = ref\n",
    "        \n",
    "        for strain in strains:\n",
    "            strain_i = strains.index(strain)\n",
    "            strain_gt = gt[strain_i]\n",
    "            if not strain_gt or strain_gt not in '012345':\n",
    "                strain_allele = '-'\n",
    "            else:\n",
    "                strain_allele = alleles[int(strain_gt)]\n",
    "            \n",
    "            site += strain_allele\n",
    "            \n",
    "        # Re-check if there are remaining invariant sites\n",
    "        bases_only = ''\n",
    "        for allele in site:\n",
    "            if allele in ['A','C','G', 'T']:\n",
    "                bases_only += allele\n",
    "\n",
    "        \n",
    "        strains_with_ref = [reference] + strains\n",
    "        \n",
    "        if len(set(bases_only)) > 1:\n",
    "                \n",
    "            for i, allele in enumerate(site):\n",
    "                strain = strains_with_ref[i]\n",
    "                strain_seqs[strain] += allele\n",
    "                            \n",
    "            keep.append((position, alleles, gt))\n",
    "            \n",
    "        else:\n",
    "            print('invariant:', fields)\n",
    "            discarded[\"Invariant\"] += 1\n",
    "\n",
    "                \n",
    "print(\"Filtered out:\")\n",
    "for k in discarded:\n",
    "    print(k, str(discarded[k]))\n",
    "    \n",
    "print(\"Kept: \", str(len(keep)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write SNP alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "\n",
    "records = []\n",
    "\n",
    "for strain in strains_with_ref:\n",
    "    sequence = Seq(strain_seqs[strain])\n",
    "    record = SeqRecord(sequence, id=strain, name=\"\", description=\"\")\n",
    "    records.append(record)\n",
    "\n",
    "SeqIO.write(records, \"SNP_alignment_from_graph.fasta\", \"fasta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an alignment with all variants, artifically coding any variant as one of four bases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "vcf = 'variants.vcf'\n",
    "\n",
    "# Ignore positions in grcC, which seems to be under convergent selection\n",
    "ignore = [\n",
    "    656926, 657255, 657265,657277, 657321, 657321, 657323  # grcC\n",
    "    ]\n",
    "\n",
    "# Load the VCF file\n",
    "with open(vcf, 'r') as vcf_file:\n",
    "    vcf_reader = csv.reader(vcf_file, delimiter='\\t')\n",
    "    # Skip the header lines\n",
    "    for _ in range(7):\n",
    "        next(vcf_reader)\n",
    "\n",
    "    # Extract the sample IDs, add reference\n",
    "    sample_ids = next(vcf_reader)[9:]\n",
    "    sample_ids.insert(0,'N1426_1')\n",
    "\n",
    "    # Initialize a dictionary to store the genotypes\n",
    "    genotypes = {sample_id: [] for sample_id in sample_ids}\n",
    "    genotypes_filtered = {sample_id: [] for sample_id in sample_ids}\n",
    "    \n",
    "    # Create artificial alignment for distance tree estimation\n",
    "    aln_artif = {sample_id: [] for sample_id in sample_ids} \n",
    "    aln_artif_filtered = {sample_id: [] for sample_id in sample_ids} \n",
    "    \n",
    "    bases = {\n",
    "        '0':'A',\n",
    "        '1':'C',\n",
    "        '2':'G',\n",
    "        '3':'T'\n",
    "    }\n",
    "    \n",
    "    # Iterate over the variants\n",
    "    for row in vcf_reader:\n",
    "        \n",
    "        pos = int(row[1])\n",
    "        \n",
    "        # Extract the genotypes\n",
    "        genotypes_row = ['0'] + row[9:]\n",
    "        for sample_id, genotype in zip(sample_ids, genotypes_row):\n",
    "            genotypes[sample_id].append(genotype)\n",
    "            aln_artif[sample_id].append(bases[genotype])\n",
    "            \n",
    "            if pos not in ignore:\n",
    "                genotypes_filtered[sample_id].append(genotype)\n",
    "                aln_artif_filtered[sample_id].append(bases[genotype])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.Seq import Seq\n",
    "from Bio import SeqIO\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "\n",
    "outhandle = open('trees/pacbio/artificial_alignment.all_variants.fasta', 'w')\n",
    "outhandle_filtered = open('trees/pacbio/artificial_alignment.all_variants.filtered.fasta', 'w')\n",
    "\n",
    "# Write artifical alignment\n",
    "for k in aln_artif:\n",
    "    \n",
    "    SeqIO.write(\n",
    "        SeqRecord(Seq(''.join(aln_artif[k])), id=k, name=\"\", description=\"\"), \n",
    "        outhandle, \"fasta\")\n",
    "    \n",
    "    SeqIO.write(\n",
    "        SeqRecord(Seq(''.join(aln_artif_filtered[k])), id=k, name=\"\", description=\"\"), \n",
    "        outhandle_filtered, \"fasta\")\n",
    "    \n",
    "outhandle.close()\n",
    "outhandle_filtered.close()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
